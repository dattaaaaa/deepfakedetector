{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7hlPaQS4e5VI"
      },
      "outputs": [],
      "source": [
        "!pip3 install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QZ22Sj8d0JoT"
      },
      "outputs": [],
      "source": [
        "# Checking if videos are corrupted or not\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "def validate_video(vid_path, train_transforms):\n",
        "      transform = train_transforms\n",
        "      count = 20\n",
        "      video_path = vid_path\n",
        "      frames = []\n",
        "      a = int(100/count)\n",
        "      first_frame = np.random.randint(0,a)\n",
        "      vid_name = video_path.split('/')[-1]\n",
        "      for i, frame in enumerate(frame_extract(video_path)):\n",
        "        frames.append(transform(frame))\n",
        "        if(len(frames) == count):\n",
        "          break\n",
        "      frames = torch.stack(frames)\n",
        "      frames = frames[:count]\n",
        "      return frames\n",
        "\n",
        "def frame_extract(path):\n",
        "  cap = cv2.VideoCapture(path) \n",
        "  status = 1\n",
        "  while status:\n",
        "      status, frame = cap.read()\n",
        "      if status:\n",
        "          yield frame\n",
        "\n",
        "im_size = 112\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.ToPILImage(),transforms.Resize((im_size,im_size)),transforms.ToTensor(),transforms.Normalize(mean,std)])\n",
        "\n",
        "video_fil = glob.glob('./dataset/videos/*.mp4')\n",
        "video_fil += glob.glob('./dataset/deepfakes/*.mp4')\n",
        "video_fil += glob.glob('./dataset/real_videos/*.mp4')\n",
        "\n",
        "print(\"Total videos found:\", len(video_fil))\n",
        "\n",
        "valid_count = 0\n",
        "corrupted_list = []\n",
        "for i in video_fil:\n",
        "  try:\n",
        "    valid_count += 1\n",
        "    validate_video(i, train_transforms)\n",
        "  except:\n",
        "    print(\"Processed:\", valid_count, \"Remaining:\", (len(video_fil) - valid_count))\n",
        "    print(\"Corrupted video:\", i)\n",
        "    corrupted_list.append(i)\n",
        "    continue\n",
        "\n",
        "print(\"Total corrupted videos:\", len(corrupted_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CEIygy8uDFXc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "import random\n",
        "\n",
        "video_files = glob.glob('./dataset/videos/*.mp4')\n",
        "video_files += glob.glob('./dataset/deepfakes/*.mp4')\n",
        "video_files += glob.glob('./dataset/real_videos/*.mp4')\n",
        "\n",
        "random.shuffle(video_files)\n",
        "\n",
        "frame_count = []\n",
        "valid_videos = []\n",
        "\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  \n",
        "  if frames < 100:\n",
        "    continue\n",
        "    \n",
        "  frame_count.append(frames)\n",
        "  valid_videos.append(video_file)\n",
        "  cap.release()\n",
        "\n",
        "print(\"Frame counts:\", frame_count)\n",
        "print(\"Total valid videos:\", len(frame_count))\n",
        "print('Average frames per video:', np.mean(frame_count))\n",
        "print('Min frames:', min(frame_count))\n",
        "print('Max frames:', max(frame_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OqGXNkqhDKZU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, video_names, labels, sequence_length=60, transform=None):\n",
        "        self.video_names = video_names\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.count = sequence_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.video_names)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.video_names[idx]\n",
        "        frames = []\n",
        "        \n",
        "        a = int(100/self.count)\n",
        "        first_frame = np.random.randint(0, a)\n",
        "        \n",
        "        video_name = video_path.split('/')[-1]\n",
        "        label_idx = self.labels.loc[self.labels[\"file\"] == video_name].index.values[0]\n",
        "        label_text = self.labels.iloc[label_idx, 1]\n",
        "        \n",
        "        if label_text == 'FAKE':\n",
        "            label = 0\n",
        "        elif label_text == 'REAL':\n",
        "            label = 1\n",
        "        \n",
        "        for i, frame in enumerate(self.frame_extract(video_path)):\n",
        "            frames.append(self.transform(frame))\n",
        "            if len(frames) == self.count:\n",
        "                break\n",
        "        \n",
        "        frames = torch.stack(frames)\n",
        "        frames = frames[:self.count]\n",
        "        \n",
        "        return frames, label\n",
        "    \n",
        "    def frame_extract(self, path):\n",
        "        cap = cv2.VideoCapture(path) \n",
        "        status = 1\n",
        "        while status:\n",
        "            status, frame = cap.read()\n",
        "            if status:\n",
        "                yield frame\n",
        "        cap.release()\n",
        "\n",
        "def display_frame(tensor):\n",
        "    image = tensor.cpu().numpy().transpose(1, 2, 0)\n",
        "    b, g, r = cv2.split(image)\n",
        "    image = cv2.merge((r, g, b))\n",
        "    \n",
        "    image = image * [0.22803, 0.22145, 0.216989] + [0.43216, 0.394666, 0.37645]\n",
        "    image = image * 255.0\n",
        "    \n",
        "    plt.imshow(image.astype(int))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1leMozhXa5LF"
      },
      "outputs": [],
      "source": [
        "# Count the number of fake and real videos in dataset\n",
        "import pandas as pd\n",
        "\n",
        "def count_real_fake_videos(video_list, metadata_path='./dataset/metadata.csv'):\n",
        "    header_list = [\"file\", \"label\"]\n",
        "    labels_df = pd.read_csv(metadata_path, names=header_list)\n",
        "    fake_count = 0\n",
        "    real_count = 0\n",
        "    unknown_count = 0\n",
        "    \n",
        "    for video_path in video_list:\n",
        "        video_name = video_path.split('/')[-1]\n",
        "        label_matches = labels_df.loc[labels_df[\"file\"] == video_name]\n",
        "        \n",
        "        if len(label_matches) > 0:\n",
        "            label_idx = label_matches.index.values[0]\n",
        "            label = labels_df.iloc[label_idx, 1]\n",
        "            \n",
        "            if label == 'FAKE':\n",
        "                fake_count += 1\n",
        "            elif label == 'REAL':\n",
        "                real_count += 1\n",
        "            else:\n",
        "                unknown_count += 1\n",
        "        else:\n",
        "            # Video not found in metadata\n",
        "            unknown_count += 1\n",
        "    \n",
        "    print(f\"Real videos: {real_count}\")\n",
        "    print(f\"Fake videos: {fake_count}\")\n",
        "    \n",
        "    if unknown_count > 0:\n",
        "        print(f\"Unknown labels: {unknown_count}\")\n",
        "        \n",
        "    return real_count, fake_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sWMZn0YHDO2b"
      },
      "outputs": [],
      "source": [
        "# Load labels and videos\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "header_list = [\"file\", \"label\"]\n",
        "labels = pd.read_csv('./dataset/metadata.csv', names=header_list)\n",
        "\n",
        "train_videos = video_files[:int(0.8*len(video_files))]\n",
        "valid_videos = video_files[int(0.8*len(video_files)):]\n",
        "\n",
        "print(\"Training set size:\", len(train_videos))\n",
        "print(\"Validation set size:\", len(valid_videos))\n",
        "\n",
        "train_real, train_fake = count_real_fake_videos(train_videos)\n",
        "valid_real, valid_fake = count_real_fake_videos(valid_videos)\n",
        "\n",
        "print(f\"TRAINING SET: Real: {train_real}, Fake: {train_fake}, Total: {train_real + train_fake}\")\n",
        "print(f\"VALIDATION SET: Real: {valid_real}, Fake: {valid_fake}, Total: {valid_real + valid_fake}\")\n",
        "\n",
        "im_size = 112\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((im_size, im_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((im_size, im_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_dataset = VideoDataset(\n",
        "    video_names=train_videos,\n",
        "    labels=labels,\n",
        "    sequence_length=10,\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "valid_dataset = VideoDataset(\n",
        "    video_names=valid_videos,\n",
        "    labels=labels,\n",
        "    sequence_length=10,\n",
        "    transform=test_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "if len(train_dataset) > 0:\n",
        "    sample_frames, sample_label = train_dataset[0]\n",
        "    display_frame(sample_frames[0])\n",
        "    print(f\"Label: {'REAL' if sample_label == 1 else 'FAKE'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UtOXSqyBDRnD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "class DeepfakeDetector(nn.Module):\n",
        "    def __init__(self, num_classes=2, latent_dim=2048, lstm_layers=1, hidden_dim=2048, bidirectional=False):\n",
        "        super(DeepfakeDetector, self).__init__()\n",
        "        backbone = models.resnext50_32x4d(pretrained=True)\n",
        "        self.feature_extractor = nn.Sequential(*list(backbone.children())[:-2])\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=latent_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batch_size, seq_length, c, h, w = x.shape\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        feature_maps = self.feature_extractor(x)\n",
        "        x = self.avgpool(feature_maps)\n",
        "        x = x.view(batch_size, seq_length, 2048)\n",
        "        x_lstm, _ = self.lstm(x, None)\n",
        "        prediction = self.classifier(self.dropout(torch.mean(x_lstm, dim=1)))\n",
        "        return feature_maps, prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WYNhn10tDV90"
      },
      "outputs": [],
      "source": [
        "model = Model(2).cuda()\n",
        "a,b = model(torch.from_numpy(np.empty((1,20,3,112,112))).type(torch.cuda.FloatTensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FKheLUWBDaNN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import os\n",
        "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    t = []\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            targets = targets.type(torch.cuda.LongTensor)\n",
        "            inputs = inputs.cuda()\n",
        "        _,outputs = model(inputs)\n",
        "        loss  = criterion(outputs,targets.type(torch.cuda.LongTensor))\n",
        "        acc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        accuracies.update(acc, inputs.size(0))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        sys.stdout.write(\n",
        "                \"\\r[Epoch %d/%d] [Batch %d / %d] [Loss: %f, Acc: %.2f%%]\"\n",
        "                % (\n",
        "                    epoch,\n",
        "                    num_epochs,\n",
        "                    i,\n",
        "                    len(data_loader),\n",
        "                    losses.avg,\n",
        "                    accuracies.avg))\n",
        "    torch.save(model.state_dict(),'/content/checkpoint.pt')\n",
        "    return losses.avg,accuracies.avg\n",
        "def test(epoch,model, data_loader ,criterion):\n",
        "    print('Testing')\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    pred = []\n",
        "    true = []\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(data_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.cuda().type(torch.cuda.FloatTensor)\n",
        "                inputs = inputs.cuda()\n",
        "            _,outputs = model(inputs)\n",
        "            loss = torch.mean(criterion(outputs, targets.type(torch.cuda.LongTensor)))\n",
        "            acc = calculate_accuracy(outputs,targets.type(torch.cuda.LongTensor))\n",
        "            _,p = torch.max(outputs,1) \n",
        "            true += (targets.type(torch.cuda.LongTensor)).detach().cpu().numpy().reshape(len(targets)).tolist()\n",
        "            pred += p.detach().cpu().numpy().reshape(len(p)).tolist()\n",
        "            losses.update(loss.item(), inputs.size(0))\n",
        "            accuracies.update(acc, inputs.size(0))\n",
        "            sys.stdout.write(\n",
        "                    \"\\r[Batch %d / %d]  [Loss: %f, Acc: %.2f%%]\"\n",
        "                    % (\n",
        "                        i,\n",
        "                        len(data_loader),\n",
        "                        losses.avg,\n",
        "                        accuracies.avg\n",
        "                        )\n",
        "                    )\n",
        "        print('\\nAccuracy {}'.format(accuracies.avg))\n",
        "    return true,pred,losses.avg,accuracies.avg\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "        \n",
        "def calculate_accuracy(outputs, targets):\n",
        "    batch_size = targets.size(0)\n",
        "\n",
        "    _, pred = outputs.topk(1, 1, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(targets.view(1, -1))\n",
        "    n_correct_elems = correct.float().sum().item()\n",
        "    return 100* n_correct_elems / batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "b8WneBZNfysN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer, checkpoint_path='./checkpoints'):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    os.makedirs(checkpoint_path, exist_ok=True)\n",
        "    \n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        # Move data to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            targets = targets.type(torch.cuda.LongTensor)\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        _, outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        acc = calculate_accuracy(outputs, targets)\n",
        "        \n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        accuracies.update(acc, inputs.size(0))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sys.stdout.write(\n",
        "            \"\\r[Epoch %d/%d] [Batch %d/%d] [Loss: %.4f, Acc: %.2f%%]\"\n",
        "            % (\n",
        "                epoch,\n",
        "                num_epochs,\n",
        "                i,\n",
        "                len(data_loader),\n",
        "                losses.avg,\n",
        "                accuracies.avg\n",
        "            )\n",
        "        )\n",
        "    \n",
        "    checkpoint_file = os.path.join(checkpoint_path, f'model_epoch_{epoch}.pt')\n",
        "    torch.save(model.state_dict(), checkpoint_file)\n",
        "    print(f\"\\nCheckpoint saved to {checkpoint_file}\")\n",
        "    \n",
        "    return losses.avg, accuracies.avg\n",
        "\n",
        "def validate(epoch, model, data_loader, criterion):\n",
        "    \n",
        "    print('\\nValidating model...')\n",
        "    \n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    \n",
        "    # Lists to store predictions and true labels\n",
        "    true_labels = []\n",
        "    predictions = []\n",
        "    \n",
        "    # Validation loop\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(data_loader):\n",
        "            # Move data to GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                targets = targets.cuda().type(torch.cuda.LongTensor)\n",
        "                inputs = inputs.cuda()\n",
        "            \n",
        "            # Forward pass\n",
        "            _, outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            \n",
        "            # Calculate accuracy\n",
        "            acc = calculate_accuracy(outputs, targets)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            # Store true labels and predictions\n",
        "            true_labels.extend(targets.cpu().numpy().tolist())\n",
        "            predictions.extend(preds.cpu().numpy().tolist())\n",
        "            \n",
        "            # Update metrics\n",
        "            losses.update(loss.item(), inputs.size(0))\n",
        "            accuracies.update(acc, inputs.size(0))\n",
        "            \n",
        "            # Print progress\n",
        "            sys.stdout.write(\n",
        "                \"\\r[Batch %d/%d] [Loss: %.4f, Acc: %.2f%%]\"\n",
        "                % (\n",
        "                    i,\n",
        "                    len(data_loader),\n",
        "                    losses.avg,\n",
        "                    accuracies.avg\n",
        "                )\n",
        "            )\n",
        "    \n",
        "    print(f'\\nValidation Accuracy: {accuracies.avg:.2f}%')\n",
        "    \n",
        "    return true_labels, predictions, losses.avg, accuracies.avg\n",
        "\n",
        "class AverageMeter(object):    \n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "        \n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def calculate_accuracy(outputs, targets):\n",
        "    batch_size = targets.size(0)\n",
        "    _, pred = outputs.topk(1, 1, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(targets.view(1, -1))\n",
        "    n_correct_elems = correct.float().sum().item()\n",
        "    return 100 * n_correct_elems / batch_size\n",
        "\n",
        "def print_metrics(true_labels, predictions):\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(true_labels, predictions, target_names=['FAKE', 'REAL']))\n",
        "    \n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "    \n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    print(f\"\\nPrecision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fExJLjt2AtV9"
      },
      "outputs": [],
      "source": [
        "def plot_loss(train_loss_avg,test_loss_avg,num_epochs):\n",
        "  loss_train = train_loss_avg\n",
        "  loss_val = test_loss_avg\n",
        "  print(num_epochs)\n",
        "  epochs = range(1,num_epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "  plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "  plt.title('Training and Validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  \n",
        "def plot_accuracy(train_accuracy,test_accuracy,num_epochs):\n",
        "  loss_train = train_accuracy\n",
        "  loss_val = test_accuracy\n",
        "  epochs = range(1,num_epochs+1)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
        "  plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "  plt.title('Training and Validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model_and_train_csv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
